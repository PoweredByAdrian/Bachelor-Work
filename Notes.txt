Pravidlová umělá inteligence (AI):
    Pravidlová AI: Postavená na předdefinovaných pravidlech a strategiích. AI provádí tahy 
        podle pevně stanovených pravidel, což může zahrnovat simulaci různých scénářů.
    Silné stránky: Jednoduchá implementace, vhodná pro hry s jasně definovanými pravidly.
    Slabé stránky: Není schopna přizpůsobit se neznámým situacím nebo se učit ze zkušeností.

Stromové vyhledávání:
    Minimax algoritmus: Algoritmus používaný v rozhodovacích a hračkových hrách pro minimalizaci možné ztráty pro 
        horší případ (maximalizaci možného zisku pro nejlepší případ) při každém tahu.
    Silné stránky: Schopnost najít optimální tahy v hrách s nulovým součtem, jako jsou šachy nebo othello.
    Slabé stránky: Náročné na zpracování v komplexních hrách s velkým prostorem stavů.

Posilování učením (Reinforcement Learning):
    Q-learning: Algoritmus strojového učení, který se snaží naučit optimální politiku pro vybraný problém rozhodování.
    Silné stránky: Schopnost adaptovat se na neznámé situace a učit se z interakcí s prostředím.
    Slabé stránky: Vyžaduje velké množství dat a času pro trénink, obtížné v oblastech s velkým prostorem stavů.

Strojové učení a neuronové sítě:
    Neuronové sítě: Síťové modely, které mohou být použity k odhadu optimálních tahů na základě tréninkových dat. 
        Mohou být použity v kombinaci s posilováním učením.
    Silné stránky: Schopnost modelovat složité vzory a strategie, efektivní ve hrách s nejasnými pravidly.
    Slabé stránky: Často vyžaduje velké množství tréninkových dat a výpočetních zdrojů.

Monte Carlo metody:
    Monte Carlo Tree Search (MCTS): Algoritmus pro hledání nejlepšího tahu ve stavovém prostoru hry pomocí
        simulací náhodných tahů a hodnocení výsledků.
    Silné stránky: Efektivní ve hrách s velkým prostorem stavů, schopnost nalézt nejlepší tahy.
    Slabé stránky: Vyžaduje mnoho simulací, což může být časově náročné.

Evoluční algoritmy:
    Genetické programování: Použití evolučních principů pro optimalizaci programů nebo strategií, které jsou následně použity AI.
    Silné stránky: Schopnost hledat globální optimum, efektivní v prostorech stavů s mnoha lokálními optimy.
    Slabé stránky: Může být pomalý a náročný na výpočetní zdroje.


Počátky:

V raných etapách deskových her nebyla umělá inteligence prominentní. Hry spoléhaly na jednoduchá pravidla a strategie.
Pravidlová AI:

Postupem času se objevily první implementace pravidlové AI, která následovala pevně stanovená pravidla a strategie. Tyto AI byly často implementovány pro konkrétní hry s jasně definovanými pravidly.
Zavedení heuristik:

S narůstající složitostí deskových her bylo potřeba sofistikovanějších přístupů. AI začala využívat heuristiky, což jsou pravidla nebo strategie založené na zkušenostech, aby rozhodla o nejlepším tahu.
Monte Carlo Tree Search (MCTS):

MCTS se stal průlomem v deskových hrách, zejména po úspěchu v hře Go. Tento algoritmus umožňuje hledání optimálních tahů ve stavovém prostoru hry pomocí simulací náhodných tahů.
Strojové učení:

Poslední dobou se stále více uplatňují metody strojového učení v deskových hrách. Neuronové sítě a algoritmy hlubokého učení jsou využívány k vytváření AI, které mohou přizpůsobit svou strategii na základě zkušeností a tréninku.
Hybridní přístupy:

V současné době se často používají hybridní přístupy, které kombinují různé techniky AI. Kombinace pravidlové AI, MCTS a strojového učení může poskytnout vyvážený a výkonný systém pro různé typy her.
Personalizace a adaptace:

Moderní trendy zahrnují personalizaci a adaptaci AI podle hráčů. AI sleduje strategie hráčů a snaží se reagovat na jejich unikátní styl hry.




https://www.sciencedirect.com/science/article/pii/S2666920X21000084

http://107.167.189.191/~vishnu/gameResearch/AI/Ghory04%20RL%20in%20board%20game.pdf

https://ojs.aaai.org/index.php/AIIDE/article/view/18700

https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Artificial+Intelligence%3A+A+Modern+Approach&btnG=

Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine learning, 8(3-4), 279-292.
Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep Learning. MIT Press.
Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P., Rohlfshagen, P., ... & Colton, S. (2012). A survey of Monte Carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 4(1), 1-43.
Koza, J. R. (1992). Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press.